#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å –∫–≤–∞–Ω—Ç–æ–≤–æ–π –∑–∞—â–∏—Ç–æ–π
A¬©tor Quantum System - –¶–µ–ø–æ—á–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏–π
"""

import os
import sys
import json
import re
import hashlib
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import tempfile

# –ò–º–ø–æ—Ä—Ç –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '07_–≠—Ç–∏—á–µ—Å–∫–∏–µ_–º–∞—Ä–∫–µ—Ä—ã'))
from quantum_auth_system import QuantumAuthSystem

@dataclass
class TranslationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤–æ–¥–∞"""
    original_text: str
    translated_text: str
    source_language: str
    target_language: str
    confidence: float
    quantum_hash: str
    auth_markers: List[str]
    distortion_detected: bool

class MultiLevelTranslationSystem:
    """–°–∏—Å—Ç–µ–º–∞ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å –∫–≤–∞–Ω—Ç–æ–≤–æ–π –∑–∞—â–∏—Ç–æ–π"""
    
    def __init__(self):
        self.quantum_auth = QuantumAuthSystem()
        self.translation_chain = []
        self.auth_markers = ["A¬©tor", "A¬©t0r"]
        
        # –¶–µ–ø–æ—á–∫–∞ —è–∑—ã–∫–æ–≤ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏–π
        self.language_chain = [
            ("ron", "eng"),  # –†—É–º—ã–Ω—Å–∫–∏–π ‚Üí –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
            ("eng", "rus"),  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π ‚Üí –†—É—Å—Å–∫–∏–π  
            ("rus", "eng"),  # –†—É—Å—Å–∫–∏–π ‚Üí –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
            ("eng", "ron")   # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π ‚Üí –†—É–º—ã–Ω—Å–∫–∏–π (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
        ]
        
        # –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.legal_terms = {
            "ron": ["articolul", "codul", "penal", "procesual", "curtea", "judecƒÉtoriei", "procuror"],
            "eng": ["article", "code", "criminal", "procedural", "court", "prosecutor", "judge"],
            "rus": ["—Å—Ç–∞—Ç—å—è", "–∫–æ–¥–µ–∫—Å", "—É–≥–æ–ª–æ–≤–Ω—ã–π", "–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π", "—Å—É–¥", "–ø—Ä–æ–∫—É—Ä–æ—Ä", "—Å—É–¥—å—è"]
        }
    
    def simulate_translation(self, text: str, source_lang: str, target_lang: str) -> Tuple[str, float]:
        """–°–∏–º—É–ª—è—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –∏—Å–∫–∞–∂–µ–Ω–∏–π"""
        
        # –ë–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ (–≤ —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã API –≤—ã–∑–æ–≤)
        translation_map = {
            ("ron", "eng"): {
                "Cerere de chemare √Æn judecatƒÉ": "Summons to court",
                "articolul": "article", 
                "codul penal": "criminal code",
                "procuror": "prosecutor",
                "judecƒÉtor": "judge"
            },
            ("eng", "rus"): {
                "Summons to court": "–í—ã–∑–æ–≤ –≤ —Å—É–¥",
                "article": "—Å—Ç–∞—Ç—å—è",
                "criminal code": "—É–≥–æ–ª–æ–≤–Ω—ã–π –∫–æ–¥–µ–∫—Å", 
                "prosecutor": "–ø—Ä–æ–∫—É—Ä–æ—Ä",
                "judge": "—Å—É–¥—å—è"
            },
            ("rus", "eng"): {
                "–í—ã–∑–æ–≤ –≤ —Å—É–¥": "Summons to court",
                "—Å—Ç–∞—Ç—å—è": "article",
                "—É–≥–æ–ª–æ–≤–Ω—ã–π –∫–æ–¥–µ–∫—Å": "criminal code",
                "–ø—Ä–æ–∫—É—Ä–æ—Ä": "prosecutor", 
                "—Å—É–¥—å—è": "judge"
            },
            ("eng", "ron"): {
                "Summons to court": "Cerere de chemare √Æn judecatƒÉ",
                "article": "articolul",
                "criminal code": "codul penal",
                "prosecutor": "procuror",
                "judge": "judecƒÉtor"
            }
        }
        
        translated = text
        confidence = 0.95
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
        for source_phrase, target_phrase in translation_map.get((source_lang, target_lang), {}).items():
            if source_phrase.lower() in translated.lower():
                translated = translated.replace(source_phrase, target_phrase)
                confidence *= 0.98  # –ù–µ–±–æ–ª—å—à–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –∫–∞–∂–¥–æ–π –∑–∞–º–µ–Ω–µ
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –∏—Å–∫–∞–∂–µ–Ω–∏–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        legal_terms_source = self.legal_terms.get(source_lang, [])
        legal_terms_target = self.legal_terms.get(target_lang, [])
        
        for term in legal_terms_source:
            if term.lower() in text.lower():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–µ—Ä–º–∏–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω
                found_correct_translation = any(
                    target_term.lower() in translated.lower() 
                    for target_term in legal_terms_target
                )
                if not found_correct_translation:
                    confidence *= 0.7  # –°–Ω–∏–∂–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–æ—Ç–µ—Ä–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        
        return translated, confidence
    
    def apply_quantum_protection(self, text: str, stage: str) -> Tuple[str, str]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–≤–∞–Ω—Ç–æ–≤–æ–π –∑–∞—â–∏—Ç—ã –∫ —Ç–µ–∫—Å—Ç—É"""
        
        # –°–æ–∑–¥–∞–µ–º –∫–≤–∞–Ω—Ç–æ–≤—ã–π —Ö–µ—à
        timestamp = datetime.now().isoformat()
        content = f"{text}_{stage}_{timestamp}"
        quantum_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã –∑–∞—â–∏—Ç—ã
        protected_text = f"{text}\n\n--- A¬©tor Quantum Protection ---\nStage: {stage}\nHash: {quantum_hash}\nTimestamp: {timestamp}"
        
        return protected_text, quantum_hash
    
    def detect_distortion(self, original: str, final: str) -> bool:
        """–î–µ—Ç–µ–∫—Ü–∏—è –∏—Å–∫–∞–∂–µ–Ω–∏–π –≤ —Ü–µ–ø–æ—á–∫–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç (–±–µ–∑ –∫–≤–∞–Ω—Ç–æ–≤—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤)
        def extract_main_text(text: str) -> str:
            lines = text.split('\n')
            main_lines = [line for line in lines if not line.startswith('---') and not line.startswith('Stage:') and not line.startswith('Hash:')]
            return '\n'.join(main_lines).strip()
        
        original_clean = extract_main_text(original)
        final_clean = extract_main_text(final)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
        original_terms = set()
        final_terms = set()
        
        for lang_terms in self.legal_terms.values():
            for term in lang_terms:
                if term.lower() in original_clean.lower():
                    original_terms.add(term.lower())
                if term.lower() in final_clean.lower():
                    final_terms.add(term.lower())
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ—Ç–µ—Ä–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        lost_terms = original_terms - final_terms
        if lost_terms:
            print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–æ—Ç–µ—Ä—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤: {lost_terms}")
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
        original_words = len(original_clean.split())
        final_words = len(final_clean.split())
        
        if abs(original_words - final_words) / original_words > 0.3:  # 30% –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
            print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞")
            return True
        
        return False
    
    def process_translation_chain(self, original_text: str, source_language: str = "ron") -> Dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
        
        print(f"üîÑ –ó–∞–ø—É—Å–∫ —Ü–µ–ø–æ—á–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ {source_language}")
        print(f"üìù –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(original_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        results = []
        current_text = original_text
        current_lang = source_language
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –∫–≤–∞–Ω—Ç–æ–≤—É—é –∑–∞—â–∏—Ç—É
        protected_text, initial_hash = self.apply_quantum_protection(current_text, "original")
        
        for i, (src_lang, target_lang) in enumerate(self.language_chain):
            if current_lang != src_lang:
                continue
                
            print(f"üîÑ –®–∞–≥ {i+1}: {src_lang} ‚Üí {target_lang}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
            translated, confidence = self.simulate_translation(current_text, src_lang, target_lang)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–≤–∞–Ω—Ç–æ–≤—É—é –∑–∞—â–∏—Ç—É
            protected_translated, quantum_hash = self.apply_quantum_protection(translated, f"step_{i+1}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–≤–∞–Ω—Ç–æ–≤—É—é —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
            quantum_verified = self.quantum_auth._verify_quantum_integrity(protected_translated)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = TranslationResult(
                original_text=current_text,
                translated_text=translated,
                source_language=src_lang,
                target_language=target_lang,
                confidence=confidence,
                quantum_hash=quantum_hash,
                auth_markers=self.auth_markers.copy(),
                distortion_detected=False
            )
            
            results.append(result)
            current_text = translated
            current_lang = target_lang
            
            print(f"‚úÖ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞: {confidence:.3f}")
            print(f"üõ°Ô∏è –ö–≤–∞–Ω—Ç–æ–≤–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è: {'–ü—Ä–æ–π–¥–µ–Ω–∞' if quantum_verified else '–ù–µ –ø—Ä–æ–π–¥–µ–Ω–∞'}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –∏—Å–∫–∞–∂–µ–Ω–∏–π
        final_text = results[-1].translated_text if results else current_text
        distortion_detected = self.detect_distortion(original_text, final_text)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if results:
            results[-1].distortion_detected = distortion_detected
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        report = {
            "translation_chain_summary": {
                "total_steps": len(results),
                "source_language": source_language,
                "final_language": current_lang,
                "original_length": len(original_text),
                "final_length": len(final_text),
                "distortion_detected": distortion_detected,
                "quantum_protection": True
            },
            "step_by_step_results": [
                {
                    "step": i + 1,
                    "source_lang": result.source_language,
                    "target_lang": result.target_language,
                    "confidence": result.confidence,
                    "quantum_hash": result.quantum_hash,
                    "text_length": len(result.translated_text)
                }
                for i, result in enumerate(results)
            ],
            "auth_markers_used": self.auth_markers,
            "processing_timestamp": datetime.now().isoformat(),
            "final_assessment": {
                "integrity_preserved": not distortion_detected,
                "average_confidence": sum(r.confidence for r in results) / len(results) if results else 0,
                "quantum_verified": all(self.quantum_auth._verify_quantum_integrity(r.translated_text) for r in results)
            }
        }
        
        return report
    
    def save_translation_results(self, report: Dict, filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"translation_chain_{timestamp}.json"
        
        output_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "03_–ü–µ—Ä–µ–≤–æ–¥—ã", filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")
        return output_path

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üåê –ó–∞–ø—É—Å–∫ Multi-Level Translation System...")
    print("üõ°Ô∏è A¬©tor Quantum Protection Enabled")
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    translation_system = MultiLevelTranslationSystem()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç (–≤ —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã —Ç–µ–∫—Å—Ç –∏–∑ OCR)
    test_text = "Cerere de chemare √Æn judecatƒÉ conform articolul 22 din codul penal. Procurorul a prezentat acuza»õiile √Æn fa»õa judecƒÉtorului."
    
    print(f"üìù –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç: {test_text}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ü–µ–ø–æ—á–∫—É –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    report = translation_system.process_translation_chain(test_text, "ron")
    
    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
    print("\nüìä –û—Ç—á–µ—Ç —Ü–µ–ø–æ—á–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤:")
    print(json.dumps(report, ensure_ascii=False, indent=2))
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    translation_system.save_translation_results(report)
    
    print("\nüîö Multi-Level Translation System –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")

if __name__ == "__main__":
    main()