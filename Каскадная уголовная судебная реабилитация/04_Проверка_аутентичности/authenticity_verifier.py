#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤
–ö–∞—Å–∫–∞–¥–Ω–∞—è —É–≥–æ–ª–æ–≤–Ω–∞—è —Å—É–¥–µ–±–Ω–∞—è —Ä–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏—è
A¬©tor Quantum System - –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
"""

import os
import sys
import json
import hashlib
import difflib
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö —Å–∏—Å—Ç–µ–º
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from quantum_auth_system import QuantumAuthSystem, JusCogensCalculator
from OCR_–æ–±—Ä–∞–±–æ—Ç–∫–∞.parallel_ocr_processor import ParallelOCRProcessor

@dataclass
class AuthenticityCheck:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏"""
    document_id: str
    original_text: str
    translated_text: str
    back_translated: str
    authenticity_score: float
    distortion_detected: bool
    quantum_verified: bool
    font_conversion_issues: List[str]
    timestamp: datetime

class AuthenticityVerifier:
    """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤"""
    
    def __init__(self):
        self.auth_system = QuantumAuthSystem()
        self.ocr_processor = ParallelOCRProcessor()
        self.jus_calculator = JusCogensCalculator(self.auth_system)
        self.verification_history = []
        
        # –ü–æ—Ä–æ–≥–∏ –æ—Ü–µ–Ω–∫–∏
        self.thresholds = {
            'minimum_authenticity': 0.7,
            'high_authenticity': 0.9,
            'critical_distortion': 0.3
        }
        
        # –Ø–∑—ã–∫–æ–≤—ã–µ –ø–∞—Ä—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        self.language_pairs = [
            ('ron', 'eng'),  # –†—É–º—ã–Ω—Å–∫–∏–π ‚Üí –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
            ('eng', 'rus'),  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π ‚Üí –†—É—Å—Å–∫–∏–π
            ('rus', 'eng'),  # –†—É—Å—Å–∫–∏–π ‚Üí –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
        ]
    
    def verify_document_authenticity(self, file_path: str, source_language: str = 'ron') -> AuthenticityCheck:
        """–ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        print(f"üîç –ù–∞—á–∞–ª–æ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏: {file_path}")
        
        # –®–∞–≥ 1: OCR –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –∑–∞—â–∏—Ç–æ–π
        ocr_result = self.ocr_processor.process_document(file_path, source_language)
        original_text = ocr_result.original_text
        
        # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ –º–∞—Ä–∫–µ—Ä–∞ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
        marked_original = self.auth_system.create_auth_marker(original_text, 'A¬©tor')
        
        # –®–∞–≥ 3: –¶–µ–ø–æ—á–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        translation_chain = self._perform_translation_chain(original_text, source_language)
        
        # –®–∞–≥ 4: –ê–Ω–∞–ª–∏–∑ –∏—Å–∫–∞–∂–µ–Ω–∏–π
        distortion_analysis = self._analyze_distortions(original_text, translation_chain)
        
        # –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
        quantum_check = self._verify_quantum_integrity(marked_original, translation_chain)
        
        # –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —à—Ä–∏—Ñ—Ç–æ–≤
        font_issues = self._check_font_conversion_issues(original_text)
        
        # –®–∞–≥ 7: –†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
        authenticity_score = self._calculate_authenticity_score(
            ocr_result, distortion_analysis, quantum_check, font_issues
        )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = AuthenticityCheck(
            document_id=self._generate_document_id(file_path),
            original_text=original_text,
            translated_text=translation_chain.get('final_translation', ''),
            back_translated=translation_chain.get('back_translation', ''),
            authenticity_score=authenticity_score,
            distortion_detected=distortion_analysis['distortion_detected'],
            quantum_verified=quantum_check['integrity_preserved'],
            font_conversion_issues=font_issues,
            timestamp=datetime.now()
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.verification_history.append(result)
        
        return result
    
    def _perform_translation_chain(self, text: str, source_lang: str) -> Dict:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        print("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤...")
        
        chain_result = {
            'original': text,
            'translations': {},
            'final_translation': '',
            'back_translation': '',
            'chain_integrity': True
        }
        
        current_text = text
        current_lang = source_lang
        
        # –¶–µ–ø–æ—á–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        for lang_pair in self.language_pairs:
            if current_lang == lang_pair[0]:
                # –ü–µ—Ä–µ–≤–æ–¥
                translation_result = self.ocr_processor.translate_and_verify(
                    current_text, current_lang, lang_pair[1]
                )
                
                if translation_result['translation_confidence'] > 0.5:
                    # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ API –ø–µ—Ä–µ–≤–æ–¥–∞
                    translated = self._simulate_translation(current_text, lang_pair[1])
                    chain_result['translations'][f"{current_lang}_{lang_pair[1]}"] = translated
                    current_text = translated
                    current_lang = lang_pair[1]
                else:
                    chain_result['chain_integrity'] = False
                    break
        
        # –û–±—Ä–∞—Ç–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        if current_lang != source_lang:
            back_translation = self._simulate_translation(current_text, source_lang)
            chain_result['back_translation'] = back_translation
        
        chain_result['final_translation'] = current_text
        
        return chain_result
    
    def _simulate_translation(self, text: str, target_lang: str) -> str:
        """–°–∏–º—É–ª—è—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
        lang_names = {
            'ron': 'Romanian',
            'rus': 'Russian', 
            'eng': 'English'
        }
        
        return f"[{lang_names.get(target_lang, target_lang)} translation]: {text[:100]}..."
    
    def _analyze_distortions(self, original: str, translation_chain: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∏—Å–∫–∞–∂–µ–Ω–∏–π –≤ —Ü–µ–ø–æ—á–∫–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
        print("üîç –ê–Ω–∞–ª–∏–∑ –∏—Å–∫–∞–∂–µ–Ω–∏–π...")
        
        analysis = {
            'distortion_detected': False,
            'distortion_score': 0.0,
            'distortion_types': [],
            'critical_changes': []
        }
        
        back_translation = translation_chain.get('back_translation', '')
        
        if back_translation:
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ —Å –æ–±—Ä–∞—Ç–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º
            similarity = difflib.SequenceMatcher(None, original, back_translation).ratio()
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∏—Å–∫–∞–∂–µ–Ω–∏—è
            if similarity < 0.7:
                analysis['distortion_detected'] = True
                analysis['distortion_score'] = 1.0 - similarity
                analysis['distortion_types'].append('significant_meaning_change')
            
            # –ü–æ–∏—Å–∫ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
            original_words = set(original.lower().split())
            back_words = set(back_translation.lower().split())
            
            missing_words = original_words - back_words
            new_words = back_words - original_words
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            legal_terms = {'—Å—É–¥', '–¥–µ–ª–æ', '–∑–∞–∫–æ–Ω', '–ø—Ä–∞–≤–æ', '—Ä–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏—è', '–∂–∞–ª–æ–±–∞', '–ø—Ä–æ–∫—É—Ä–æ—Ä'}
            
            critical_missing = missing_words.intersection(legal_terms)
            critical_new = new_words.intersection(legal_terms)
            
            if critical_missing or critical_new:
                analysis['distortion_detected'] = True
                analysis['critical_changes'].extend(list(critical_missing))
                analysis['critical_changes'].extend(list(critical_new))
                analysis['distortion_types'].append('legal_terms_altered')
        
        return analysis
    
    def _verify_quantum_integrity(self, marked_text: str, translation_chain: Dict) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏"""
        print("‚öõÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏...")
        
        integrity_check = {
            'integrity_preserved': True,
            'marker_intact': True,
            'quantum_hash_valid': True,
            'parallel_computation_ok': True
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Ä–∫–µ—Ä–∞ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        original_verification = self.auth_system.verify_authenticity(marked_text)
        integrity_check['marker_intact'] = original_verification['authentic']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –≤ —Ü–µ–ø–æ—á–∫–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        for step, translation in translation_chain.get('translations', {}).items():
            step_verification = self.auth_system.verify_authenticity(translation)
            if not step_verification['authentic']:
                integrity_check['integrity_preserved'] = False
                break
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        parallel_check = self.auth_system.parallel_computation_check(marked_text)
        integrity_check['parallel_computation_ok'] = parallel_check['parallel_integrity']
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        integrity_check['integrity_preserved'] = all([
            integrity_check['marker_intact'],
            integrity_check['quantum_hash_valid'],
            integrity_check['parallel_computation_ok']
        ])
        
        return integrity_check
    
    def _check_font_conversion_issues(self, text: str) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–±–ª–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —à—Ä–∏—Ñ—Ç–æ–≤"""
        issues = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
        try:
            text.encode('cp1251')
        except UnicodeEncodeError:
            issues.append('cyrillic_encoding_issue')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä—É–º—ã–Ω—Å–∫–∏–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
        romanian_chars = 'ƒÉ√¢√Æ»ô»õƒÇ√Ç√é»ò»ö'
        if any(char in text for char in romanian_chars):
            try:
                text.encode('latin2')
            except UnicodeEncodeError:
                issues.append('romanian_diacritics_issue')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ—Ç–µ—Ä—é —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if '\t' in text or '  ' in text:
            issues.append('formatting_loss_detected')
        
        return issues
    
    def _calculate_authenticity_score(self, ocr_result, distortion_analysis, 
                                   quantum_check, font_issues) -> float:
        """–†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏"""
        base_score = 1.0
        
        # OCR —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        ocr_weight = 0.3
        base_score -= (1.0 - ocr_result.confidence) * ocr_weight
        
        # –ò—Å–∫–∞–∂–µ–Ω–∏—è
        if distortion_analysis['distortion_detected']:
            distortion_weight = 0.4
            base_score -= distortion_analysis['distortion_score'] * distortion_weight
        
        # –ö–≤–∞–Ω—Ç–æ–≤–∞—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
        if not quantum_check['integrity_preserved']:
            quantum_weight = 0.2
            base_score -= quantum_weight
        
        # –ü—Ä–æ–±–ª–µ–º—ã —à—Ä–∏—Ñ—Ç–æ–≤
        if font_issues:
            font_weight = 0.1
            base_score -= len(font_issues) * font_weight
        
        return max(0.0, min(1.0, base_score))
    
    def _generate_document_id(self, file_path: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        timestamp = datetime.now().isoformat()
        file_hash = hashlib.md5(file_path.encode()).hexdigest()[:8]
        return f"doc_{file_hash}_{timestamp}"
    
    def generate_authenticity_report(self, checks: List[AuthenticityCheck]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏"""
        report = {
            'verification_summary': {
                'total_documents': len(checks),
                'authentic_documents': sum(1 for c in checks if c.authenticity_score >= self.thresholds['minimum_authenticity']),
                'high_authenticity': sum(1 for c in checks if c.authenticity_score >= self.thresholds['high_authenticity']),
                'distorted_documents': sum(1 for c in checks if c.distortion_detected),
                'quantum_verified': sum(1 for c in checks if c.quantum_verified)
            },
            'average_scores': {
                'authenticity': sum(c.authenticity_score for c in checks) / max(len(checks), 1),
                'distortion_level': sum(1 for c in checks if c.distortion_detected) / max(len(checks), 1)
            },
            'font_issues_summary': {},
            'verification_timestamp': datetime.now().isoformat(),
            'detailed_checks': []
        }
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º —Å —à—Ä–∏—Ñ—Ç–∞–º–∏
        for check in checks:
            for issue in check.font_conversion_issues:
                report['font_issues_summary'][issue] = report['font_issues_summary'].get(issue, 0) + 1
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for check in checks:
            report['detailed_checks'].append({
                'document_id': check.document_id,
                'authenticity_score': check.authenticity_score,
                'distortion_detected': check.distortion_detected,
                'quantum_verified': check.quantum_verified,
                'font_issues_count': len(check.font_conversion_issues),
                'verification_timestamp': check.timestamp.isoformat()
            })
        
        return json.dumps(report, ensure_ascii=False, indent=2)
    
    def batch_verify_documents(self, directory: str, file_pattern: str = "*.pdf") -> List[AuthenticityCheck]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        print(f"üìÅ –ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏: {directory}")
        
        import glob
        files = glob.glob(os.path.join(directory, file_pattern))
        results = []
        
        for file_path in files:
            try:
                result = self.verify_document_authenticity(file_path)
                results.append(result)
                print(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω: {os.path.basename(file_path)} - {result.authenticity_score:.2f}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ {file_path}: {str(e)}")
        
        return results

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
    print("üõ°Ô∏è –ó–∞–ø—É—Å–∫ Authenticity Verifier...")
    print("‚öõÔ∏è A¬©tor Quantum System - –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    verifier = AuthenticityVerifier()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    sample_text = "Acest text este protejat de sistemul cuantic A¬©tor"
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    sample_check = AuthenticityCheck(
        document_id="test_doc_001",
        original_text=sample_text,
        translated_text="[English translation]: This text is protected by the quantum system A¬©tor",
        back_translated="[Russian translation]: –≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç –∑–∞—â–∏—â–µ–Ω –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π A¬©tor",
        authenticity_score=0.95,
        distortion_detected=False,
        quantum_verified=True,
        font_conversion_issues=[],
        timestamp=datetime.now()
    )
    
    print(f"üìä –û–±—Ä–∞–∑–µ—Ü –ø—Ä–æ–≤–µ—Ä–∫–∏: {sample_check}")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report = verifier.generate_authenticity_report([sample_check])
    print(f"üìã –û—Ç—á–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: {report}")
    
    print("üîö –í–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")

if __name__ == "__main__":
    main()