#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCR —Å–∏—Å—Ç–µ–º–∞ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏
–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä—É–º—ã–Ω—Å–∫–∏—Ö/—Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –∏—Å–∫–∞–∂–µ–Ω–∏–π
A¬©tor Quantum System
"""

import os
import sys
import subprocess
import json
import re
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import tempfile

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–µ–π –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '07_–≠—Ç–∏—á–µ—Å–∫–∏–µ_–º–∞—Ä–∫–µ—Ä—ã'))
from quantum_auth_system import QuantumAuthSystem, JusCogensCalculator

@dataclass
class OCRResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    original_text: str
    protected_text: str
    confidence: float
    language_detected: str
    auth_markers: List[str]
    quantum_verified: bool
    
class ParallelOCRProcessor:
    """OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏"""
    
    def __init__(self):
        self.auth_system = QuantumAuthSystem()
        self.jus_calculator = JusCogensCalculator(self.auth_system)
        self.processing_log = []
        
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏
        self.languages = {
            'ron': 'Romanian',
            'rus': 'Russian', 
            'eng': 'English'
        }
        
        # –®—Ä–∏—Ñ—Ç—ã –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        self.font_mapping = {
            'Times New Roman': 'Consolas',
            'Arial': 'Courier New',
            'Calibri': 'Lucida Console'
        }
    
    def process_document(self, file_path: str, source_language: str = 'ron') -> OCRResult:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –ø–æ–ª–Ω—ã–º —Ü–∏–∫–ª–æ–º –∑–∞—â–∏—Ç—ã"""
        print(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {file_path}")
        
        # –®–∞–≥ 1: OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        raw_text = self._perform_ocr(file_path, source_language)
        
        # –®–∞–≥ 2: –ó–∞—â–∏—Ç–∞ –∫–≤–∞–Ω—Ç–æ–≤—ã–º–∏ –º–∞—Ä–∫–µ—Ä–∞–º–∏
        protected_text = self.auth_system.create_auth_marker(raw_text, 'A¬©tor')
        
        # –®–∞–≥ 3: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —à—Ä–∏—Ñ—Ç–æ–≤
        font_converted = self.auth_system.convert_font_encoding(
            protected_text, 'Times New Roman', 'Consolas'
        )
        
        # –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        parallel_check = self.auth_system.parallel_computation_check(font_converted)
        
        # –®–∞–≥ 5: –†–∞—Å—á–µ—Ç jus cogens
        jus_calculation = self.jus_calculator.calculate_jus_cogens(font_converted)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = OCRResult(
            original_text=raw_text,
            protected_text=font_converted,
            confidence=self._calculate_confidence(raw_text),
            language_detected=self._detect_language(raw_text),
            auth_markers=['A¬©tor'],
            quantum_verified=parallel_check['parallel_integrity']
        )
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_record = {
            'file_path': file_path,
            'timestamp': datetime.now().isoformat(),
            'language': source_language,
            'confidence': result.confidence,
            'quantum_verified': result.quantum_verified,
            'jus_cogens_score': jus_calculation['jus_cogens_score']
        }
        
        self.processing_log.append(processing_record)
        
        return result
    
    def _perform_ocr(self, file_path: str, language: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ OCR —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Tesseract
            result = subprocess.run([
                'tesseract', file_path, 'stdout', '-l', language
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                return result.stdout.strip()
            else:
                print(f"‚ö†Ô∏è Tesseract –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥")
                return self._fallback_text_extraction(file_path)
                
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print(f"‚ö†Ô∏è OCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞")
            return self._fallback_text_extraction(file_path)
    
    def _fallback_text_extraction(self, file_path: str) -> str:
        """–ó–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤
            if file_path.lower().endswith('.pdf'):
                # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF
                with open(file_path, 'rb') as f:
                    content = f.read()
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Ç–∞–µ–º—ã—Ö —Å—Ç—Ä–æ–∫
                text_parts = []
                current_text = ""
                
                for byte in content:
                    if 32 <= byte <= 126:  # –ü–µ—á–∞—Ç–∞–µ–º—ã–µ ASCII —Å–∏–º–≤–æ–ª—ã
                        current_text += chr(byte)
                    else:
                        if len(current_text) > 10:
                            text_parts.append(current_text)
                        current_text = ""
                
                if current_text:
                    text_parts.append(current_text)
                
                return ' '.join(text_parts)
            
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
            else:
                return f"[–¢–ï–ö–°–¢ –ò–ó –§–ê–ô–õ–ê: {os.path.basename(file_path)}]"
                
        except Exception as e:
            return f"[–û–®–ò–ë–ö–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø: {str(e)}]"
    
    def _calculate_confidence(self, text: str) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ OCR"""
        if not text or text.startswith('['):
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
        base_confidence = min(len(text) / 1000, 1.0)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        if any(word in text.lower() for word in ['—Å—É–¥', '–¥–µ–ª–æ', '–∑–∞–∫–æ–Ω', '–ø—Ä–∞–≤–æ']):
            base_confidence += 0.2
        
        return min(base_confidence, 1.0)
    
    def _detect_language(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return 'unknown'
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞
        romanian_chars = set('ƒÉ√¢√Æ»ô»õƒÇ√Ç√é»ò»ö')
        russian_chars = set('—ë—ä—ã—ç–Å–™–´–≠')
        
        text_lower = text.lower()
        
        romanian_count = sum(1 for char in text_lower if char in romanian_chars)
        russian_count = sum(1 for char in text_lower if char in russian_chars)
        
        if romanian_count > russian_count:
            return 'Romanian'
        elif russian_count > 0:
            return 'Russian'
        else:
            return 'Unknown'
    
    def translate_and_verify(self, text: str, source_lang: str, target_lang: str) -> Dict:
        """–ü–µ—Ä–µ–≤–æ–¥ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏"""
        print(f"üîÑ –ü–µ—Ä–µ–≤–æ–¥: {source_lang} ‚Üí {target_lang}")
        
        # –®–∞–≥ 1: –ó–∞—â–∏—Ç–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        protected_original = self.auth_system.create_auth_marker(text, 'A¬©tor')
        
        # –®–∞–≥ 2: –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ (–≤ —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã API –≤—ã–∑–æ–≤)
        translated_text = self._simulate_translation(text, source_lang, target_lang)
        
        # –®–∞–≥ 3: –ó–∞—â–∏—Ç–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        protected_translation = self.auth_system.create_auth_marker(translated_text, 'A¬©t0r')
        
        # –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –æ–±–æ–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
        original_auth = self.auth_system.verify_authenticity(protected_original)
        translation_auth = self.auth_system.verify_authenticity(protected_translation)
        
        # –®–∞–≥ 5: –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        comparison_result = {
            'original_verified': original_auth['authentic'],
            'translation_verified': translation_auth['authentic'],
            'distortion_detected': translation_auth['distortion_detected'],
            'quantum_integrity_preserved': original_auth['authentic'] and translation_auth['authentic'],
            'translation_confidence': self._calculate_translation_confidence(text, translated_text)
        }
        
        return comparison_result
    
    def _simulate_translation(self, text: str, source_lang: str, target_lang: str) -> str:
        """–°–∏–º—É–ª—è—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ (–∑–∞–≥–ª—É—à–∫–∞)"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ API –ø–µ—Ä–µ–≤–æ–¥–∞
        language_map = {
            ('ron', 'eng'): '[Romanian to English translation]',
            ('eng', 'rus'): '[English to Russian translation]', 
            ('rus', 'eng'): '[Russian to English translation]'
        }
        
        key = (source_lang[:3], target_lang[:3])
        prefix = language_map.get(key, f'[{source_lang} to {target_lang} translation]')
        
        return f"{prefix}: {text[:100]}..." if len(text) > 100 else f"{prefix}: {text}"
    
    def _calculate_translation_confidence(self, original: str, translation: str) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        if not original or not translation:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        original_words = len(original.split())
        translation_words = len(translation.split())
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –¥–ª–∏–Ω
        length_ratio = min(translation_words / max(original_words, 1), 2.0)
        
        # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence = 0.7
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é –¥–ª–∏–Ω
        if 0.5 <= length_ratio <= 2.0:
            confidence += 0.2
        
        return min(confidence, 1.0)
    
    def batch_process_documents(self, directory: str, file_pattern: str = "*.pdf") -> List[OCRResult]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        print(f"üìÅ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {directory}")
        
        results = []
        
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
        import glob
        files = glob.glob(os.path.join(directory, file_pattern))
        
        for file_path in files:
            try:
                result = self.process_document(file_path)
                results.append(result)
                print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {os.path.basename(file_path)}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {str(e)}")
        
        return results
    
    def generate_processing_report(self, results: List[OCRResult]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—Ä–∞–±–æ—Ç–∫–µ"""
        report = {
            'processing_summary': {
                'total_documents': len(results),
                'successful_processing': sum(1 for r in results if r.confidence > 0),
                'quantum_verified': sum(1 for r in results if r.quantum_verified),
                'average_confidence': sum(r.confidence for r in results) / max(len(results), 1)
            },
            'language_distribution': {},
            'auth_markers_used': list(set(marker for r in results for marker in r.auth_markers)),
            'processing_timestamp': datetime.now().isoformat(),
            'detailed_results': []
        }
        
        # –ê–Ω–∞–ª–∏–∑ —è–∑—ã–∫–æ–≤
        for result in results:
            lang = result.language_detected
            report['language_distribution'][lang] = report['language_distribution'].get(lang, 0) + 1
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for i, result in enumerate(results):
            report['detailed_results'].append({
                'document_index': i,
                'confidence': result.confidence,
                'language': result.language_detected,
                'quantum_verified': result.quantum_verified,
                'text_length': len(result.original_text),
                'auth_markers': result.auth_markers
            })
        
        return json.dumps(report, ensure_ascii=False, indent=2)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    print("üîç –ó–∞–ø—É—Å–∫ Parallel OCR Processor...")
    print("üõ°Ô∏è A¬©tor Quantum Protection Enabled")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    processor = ParallelOCRProcessor()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    sample_text = "Acesta este o probƒÉ de text √Æn limba rom√¢nƒÉ"
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
    translation_result = processor.translate_and_verify(sample_text, 'ron', 'eng')
    print(f"üîÑ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤–æ–¥–∞: {translation_result}")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    sample_results = [
        OCRResult(
            original_text=sample_text,
            protected_text=processor.auth_system.create_auth_marker(sample_text),
            confidence=0.95,
            language_detected='Romanian',
            auth_markers=['A¬©tor'],
            quantum_verified=True
        )
    ]
    
    report = processor.generate_processing_report(sample_results)
    print(f"üìä –û—Ç—á–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {report}")
    
    print("üîö OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")

if __name__ == "__main__":
    main()